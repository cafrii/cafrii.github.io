---
layout: post
title:  "AI Perspective on GROK3 release"
category: ai
tags: ai
---


## GROK3 릴리즈


딥시크에 이어서 딥리서치, 그리고 이제 또 GROK3 까지. 정말이지 정신 없이 새로운 AI 소식들이 쏟아지는 시기 입니다. 블로그를 만들면서, AI 관련해서 스터디 한 내용들도 정리해 보면 좋겠다 라는 생각은 했지만, 그러할 시간을 내는 것은 당분간 힘들거 같고, 그냥 최신 뉴스 만이라도 요약 정리하는 것이라도 시작해야 겠다는 생각이 들었습니다.

지금은 비팩토리의 대표이신, 노정석 대표님의 강의 중에, 꼭 발췌해 두고 싶은 부분이 있어서 먼저 짚어 봅니다.

> 그리고 이제 그 사이에 썼던 여러 가지 팁들을 보여주는데,
> 뭐냐면 저희 모델이 뭔가 물어보면 쭈루룩 답을 하고 끝나는 거에서 그냥 그 엔드 오브 센텐스 토큰이 나오잖아요.
> 그러면 엔드 오브 센텐스 토큰이 나오면 그걸로 종료하는 게 아니라, 걔를 "wait", "기다려", "한 번 더 생각해봐" 라는 걸로 그냥 다시 대체를 하면,
> 모델이 당황하면서 "내가 틀린 건가?" 라고 하면서 생각을 더 깊게 하더라.
> 이거 참 웃기는 얘기죠.
> 그리고 또 너무 중언부언하면서 말을 많이 하면 그냥 강제로 끊어버리고, 이런 식으로 이걸 버짓 폴싱이라고 애들이 얘기를 하는데, ...

여전히 인간은 AI를 발견하고 있는 단계인 것 같습니다.
이런 걸 보면 파운데이션 모델을 만드는 사람들은 탐험가 같아 보입니다.

아래 내용은 2025.2.23 일에 올라온 노정석 대표님의 유튜브 동영상 중 GROK3 발표를 맞아 AI 에 대한 내용을 정리하신 글입니다. 미처 요약에 포함되지 못한 깨알같은 중요 내용이 많으므로 원문을 보시길 권장합니다.

원문 출처: <https://youtu.be/Ke8IxrUTpD0>

본 글에 대한 일체의 권리는 원작자에게 있습니다.
이 주제의 특성 상 읽는 시점에 따라 상황이 많이 달라질 수 있다는 점에 유의하세요.

##

### 목차
1. AI의 급속한 발전과 주요 발표들
2. 컴퓨터의 발전과 GROK3의 성능 분석
3. 알고리즘 발전 방향 및 데이터 효율성
4. AI 모델의 발전과 선순환 구조
5. 인공지능의 가격과 서비스의 미래 방향


## 서론
이번 에피소드는 AI의 급속한 발전을 다루며, 특히 GROK3와 관련된 여러 최신 기술적 변화에 대한 통찰을 제공합니다. AI 분야에서 매일 발표되는 논문과 기술들이 어떻게 우리의 미래를 형성하는지를 살펴보며, 올바른 데이터의 중요성과 성능 향상에 대한 스케일링 문제를 논의합니다. 전반적으로 AI 기술의 컴퓨테이션 총량 증가가 가져오는 변화와 그로 인한 서비스 시장의 변화도 강조됩니다. AI가 우리 생활의 필수 요소로 자리 잡고 있으며, 그 경쟁이 가격을 제로 수렴하게 할 것이라는 관점도 인지하게 됩니다. 결국, 이런 모든 변화 속에서 중요한 것은 품질 좋은 데이터와 이를 통해 가치를 창출하는 것입니다.


## 1. AI의 급속한 발전과 주요 발표들

* 2025년 2월 23일, 미국 출장을 와 있는 중이며 시차 관계로 단독으로 메시지를 전달하고 있다.
* 챗GPT가 2022년 11월에 출시된 이후로, AI 발전과 새로운 소식의 주기가 점점 짧아지고 있다.
* archive.org 에서는 하루에 AI 관련 논문이 최소 500개에서 1000개까지 올라온다.
* 12월 오픈AI의 GPT-3 발표와 1월 딥마인드의 Sparrow-1 발표를 통해 '딥마인드 쇼크'가 있었다.
* 최근에는 일론 머스크가 Grok-3를 발표하고, 구글이 코사이언티스트 논문을 게재하며 주목받고 있다.

## 2. 컴퓨터의 발전과 GROK3의 성능 분석

* 엔비디아 GPU는 딥러닝의 주요 컴퓨테이션 자원으로, 특히 H100 출시 이후로 컴퓨테이션 총량이 빠르게 증가하고 있으며, 이는 향후 AI 성능에 긍정적인 영향을 미칠 가능성이 있다.
* 일론 머스크는 자신의 데이터센터에 20만 개의 GPU를 빠르게 배치하여 컴퓨테이션 총량을 늘렸으며, 이는 품질 높은 프론티어 모델 개발에 기여한다.
* GROK3는 이전 모델인 GROK2에 비해 10배의 컴퓨테이션을 사용했지만, 성능 향상은 상대적으로 적을 것으로 예상되며, 10배 컴퓨테이션 증가 시 로스가 24% 감소하는 스케일링 로우를 언급한다.
* AI 모델의 품질이 상향 평준화되고 있어, 여러 업체들이 공통적으로 높은 성능을 달성하고 있으며, 특히 오픈AI의 경쟁력이 어느 정도 감소하고 있는 상황임을 강조한다.
* 아이디어 경제와 관련하여 빅테크 기업들이 경쟁하며, AI 인텔리전스의 가격이 지속적으로 하락하는 현상이 발생하고 있다, 궁극적으로 가격이 0으로 수렴할 가능성이 크다고 전망한다.

## 3. 알고리즘 발전 방향 및 데이터 효율성

* 최근 알고리즘의 발전은 엔비디아 GPU 하드웨어 최적화와 트랜스포머 구조에 중점을 두고 있으며, 데이터와 컴퓨터 효율성 개선이 주를 이루고 있다.
* 딥러닝의 V3 페이퍼는, FP8의 활용과 텐서코어를 통한 유틸리제이션 개선을 다루고 있으며, MOE, MLA, 멀티헤드 어텐션 등의 기술적 접근에 관한 내용이 많이 포함되어 있다.
* 에이전트 시스템 설계에 대한 최근 연구들에서는 프롬프트를 통해 모델을 제어하고, 여러 에이전트를 조합하여 과업을 수행하는 형태로 시스템이 구성되고 있다.
* DeepMind의 R1 페이퍼는 강화 학습을 통해 인스트럭트 모델을 추론 모델로 전환하는 가능한 방법에 대해 논의하며, 큰 데이터셋 없이도 효과적인 강화 학습 결과를 보여준다.
* 고품질의 데이터셋 1,000개만으로도 기존 모델의 성능을 뛰어넘는 가능성을 제시하며, "textbook is all you need" 라는 주장은 데이터 품질의 중요성을 강조한다.



### 3.1. 딥러닝 알고리즘 발전 방향
* 최근 딥러닝 알고리즘의 발전은 엔비디아 GPU 하드웨어에 최적화되는 경향을 보인다.
* 트랜스포머 구조의 활용이 데이터 효율과 컴퓨터 효율성을 개선하는 주된 방법으로 서술된다.
* 딥러닝 V3 페이퍼에서는 H800 네트워크의 제한된 성능을 극대화하기 위한 최적화 사례가 포함되어 있으며, 이는 역시 엔비디아 GPU 최적화와 관련이 있다.
* FP8 활용 및 텐서코어의 유용성을 극대화하려는 시도가 주를 이루고 있고, 다양한 어텐션 기법의 효율화가 논의된다.
* 데이터 효율화를 위한 새로운 방법론이 제시되고 있지만, 이런 엔지니어링적 과정의 중요성이 부각되고 있다.

### 3.2. 최근 AI 동향 및 발전 키워드
* 구글 타이탄이 현재 트레인을 걸고 있다는 소문이 있으며, 아직 리뷰는 진행되지 않은 상태이다.
* 최근 로봇 기술이 핫한 이슈가 되고 있으며, Figure.ai와 감마 등의 발표가 잇따르고 있다.
* VLA(Vision Language Action) 모델을 둘러싼 스페이스가 강화되고 있는 추세이다.
* 가장 중요한 키워드는 TTC(Test Time Computation)로, 이는 중요한 AI 발전의 방향성을 시사한다.
* TTC는 테스트 타임 컴퓨터를 활용하여 미지의 세계를 탐색하는 기술을 의미한다.

### 3.3. 에이전트 시스템과 최적화의 발전
* 딥마인드의 멀티 에이전트 시스템 설계 논문에서는 에이전트 모델의 제어를 프롬프트와 펑션콜을 통해 수행하는 방법을 제시한다.
* 에이전트 시스템은 여러 개의 에이전트를 적절한 구조로 묶어 과업을 해결하는 형태로 구성되며, 이는 컴퓨테이션 기반 최적화를 통해 가능해진다.
* '컴퓨트 이퀄 인텔리전스'라는 개념이 강조되며, 모델 학습과정에서 최적화가 핵심임을 나타낸다.
트레이닝된 모델은 Chain of Thought (CoT) 방법론을 통해 성능을 향상시킬 수 있으며, 3백만 모델이 7천만 모델의 성능에 근접할 수 있음이 나타난다.
* 딥마인드는 증류(distillation) 방식으로 작은 모델도 좋은 추론 모델로 변화시킬 수 있음을 보여주며, 이는 SFT(Supervised Fine Tuning)를 통해 이루어진다.

### 3.4. 프론티어 모델과 데이터셋 생성
* 연구자는 뷰티 도메인 특화 리즈닝 데이터셋 60만 개를 만드는 아이디어를 갖고 있으며, 이는 각자의 도메인에서도 가능하다고 생각한다.
* 질문과 정답이 명확하게 구분되는 영역은 수학, 과학, 코딩과 같은 분야이며, 이들 분야는 현재 급速 발전 중이다.
* 많은 도메인에서는 검증 가능한 정답이 없는 경우가 많고, 뷰티 영역도 그런 사례 중 하나이다.
모델이 여러 개의 답변을 생성하게 하고, 그중 정답 비율이 높은 것을 선택하는 방식으로 데이터셋을 만들 수 있다는 생각을 하고 있다.
* 스탠포드에서 발표한 S1 논문 연구에 따르면, 59,000개 데이터 대신 1,000개의 고품질 고난도 샘플만으로도 충분한 성능을 낼 수 있다고 한다.

### 3.5. AI 모델의 데이터 품질과 접근 방식
* 모델이 답변을 종료할 때 "엔드 오브 센텐스 토큰"을 단순히 끝내지 않고 "기다려" 등의 요청으로 대체하면 모델이 더 깊이 생각하게 된다.
* 데이터의 양보다 질이 더 중요하며, 좋은 데이터셋은 기존 모델을 reasoning 모델로 변환할 수 있는 강력한 힘을 가진다.
* 1,000개의 고품질 데이터만으로도 QWEN 320억 인스트럭트 모델의 성능을 향상시킬 수 있음을 주장한다.
* 고품질 데이터를 생산하는 데 대한 고민은 여러 분야의 전문가들 사이에서 공통적으로 이루어질 것이다.
* 데이터셋의 품질 향상이 이루어질 경우, 프론티어 모델에 준하는 성능을 달성할 가능성이 있으며, 실험 결과는 상황에 따라 다르게 나타날 수 있다.

## 4. AI 모델의 발전과 선순환 구조

* 프론티어 모델의 품질이 좋아짐에 따라, 우수한 인공 데이터셋이 생성되고 있어, 이는 다음 세대 모델과 작은 모델의 품질 향상으로 이어진다.
* 리즈닝 모델과 인스트럭트 모델의 경계가 사라지고 있으며, Sam Altman은 GPT-5에서 이 경계가 없어질 것이라고 언급했다.
* 어려운 문제를 처음 풀고 외우면, 이후에는 간단하게 답을 도출할 수 있으며, 이는 공식처럼 이해되는 과정과 유사하다.
* 계속해서 모델에 과제를 부여하면 좋은 데이터셋이 생산되고, 이는 다시 다음 세대 모델 훈련에 활용되어 더욱 발전한다.
* 이러한 발전은 아티피셜 슈퍼 인텔리전스의 출현으로 이어질 것으로 예상되며, 그 타이밍을 예측하는 것이 중요하다.

## 5. 인공지능의 가격과 서비스의 미래 방향

* 컴퓨터 및 알고리즘 관련 논쟁이 더 이상 의미가 없으며, 부가가치 창출에 집중해야 하는 시점이라고 판단된다.
* 인텔리전스의 가격이 0원으로 수렴해 갈 것으로 예상되며, 소비자들은 필요한 업무를 처리할 수 있는 가장 저렴한 모델을 찾을 것이라는 점이 중요하다.
* 경쟁이 활성화되면 인텔리전스 서비스의 가격이 거의 0원에 가까워질 것으로 보이며, 이는 소비자에게 혜택이 돌아가는 구조이다.
* 앞으로 모든 가정에 인텔리전스 아울렛과 같은 API가 보편화될 것이며, 이는 우리 삶의 편리함을 더해줄 다양한 가전제품들로 이어질 것이다.
* AI 엔지니어 서밋에서는 에이전트라는 키워드를 통해 AI 서비스가 급격히 성장하고 있다는점이 강조되며, 앞으로 코딩 분야에서도 사람들을 대체할 가능성이 높아 보인다.

